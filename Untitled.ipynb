{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from shapely.geometry import shape, Point \n",
    "import folium\n",
    "from matplotlib.pyplot import axis\n",
    "from numpy import shape\n",
    "\n",
    "import copy\n",
    "import matplotlib\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "#os.environ['SPARK_CLASSPATH'] = './spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar'\n",
    "#os.environ['SPARK_CLASSPATH'] = './spark-sql-kafka-0-10_2.11-2.3.0.jar'\n",
    "'''if(False):\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0 \\\n",
    "    --archives pySparkEnv.zip\\\n",
    "    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./pySparkEnv/pySparkEnv/bin/python\"\n",
    "else:\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0'\n",
    "    '''\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"/gpfs/smartdata/urdxb/.conda/envs/pySparkEnv/bin/ipython\"\n",
    "os.environ['PYSPARK_PYTHON'] = \"/gpfs/smartdata/urdxb/.conda/envs/pySparkEnv/bin/python\"\n",
    "#    Spark\n",
    "from pyspark import SparkContext\n",
    "#    Spark Streaming\n",
    "from pyspark.streaming import StreamingContext  \n",
    "#    Kafka\n",
    "from pyspark.streaming.kafka import KafkaUtils  \n",
    "#    json parsing\n",
    "import json \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "#https://spark.apache.org/docs/2.3.0/structured-streaming-kafka-integration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").setAppName('pyspark')#.set(\"spark.jars\", \"./spark-sql-kafka-0-10_2.11-2.3.0.jar\")\n",
    "ss = SparkSession.builder.config(conf=SparkConf()).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2], [0, 1, 2, 3], [0, 1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "## On spark on one node because of numpy\n",
    "playRdd = ss.sparkContext.parallelize([range(3),range(4),range(5)])\n",
    "\n",
    "\n",
    "print(playRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]',\n",
       " '2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]',\n",
       " '2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mySum(x):\n",
    "    import sys\n",
    "    return sys.version\n",
    "playRdd.map(mySum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pySparkEnv]",
   "language": "python",
   "name": "conda-env-pySparkEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
